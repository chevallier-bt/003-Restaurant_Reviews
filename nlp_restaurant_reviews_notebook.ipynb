{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Restaurant Reviews NLP implementation\n",
        "This is my first project on DataBricks AWS using PySpark. This is my first NLP problem in ML.\n",
        "\n",
        "## Objective\n",
        "Categorize customer sentiment using the provided review. The provided dataset has"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d26c1503-3fc5-469d-890f-516d2a697445"
        },
        "id": "A8hop0bM0W0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Familiarizing\n",
        "There are several practices in NLP that need just a bit of exploration. In order:\n",
        "* Tokenization\n",
        "  * Splitting of sentences into individual words for further processing, seems to be one of the first steps in NLP data preparation.\n",
        "* Stop-Word Removal\n",
        "  * Removal of unnecessary words which do not provide any contextual meaning to the sentences. Words like 'the', 'of', 'to', etc.\n",
        "* N-Grams\n",
        "  * Grouping of individual words into n-long 'sentences'. This can be useful for identifying particular n-grams which can provide important information. Things such as 'tasted bad', 'great price', etc.\n",
        "* Term Frequency\n",
        "  * Checking the frequency of particular terms, which may or may not have correlation with outputs. Inverse frequency is also commonly used under the following principle: Words that appear exceedingly often most likely have less unique actionable information than less-frequent words. For exmaple, comparing 'stellar' with 'okay'."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c3efc7b9-b738-49a9-bda8-c40be17fd709"
        },
        "id": "AXPtsmTD0W0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType, StringType, StructField, StructType, BooleanType, ArrayType, TimestampType"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "3ae366e4-c7df-46b9-8aec-3fc760c18a87"
        },
        "id": "Gwfaiin10W0O",
        "outputId": "5abaf3e0-a95f-40ae-ce1d-dcf83ec01be7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = sqlContext.sql(\"Select * FROM nlp_restaurant_reviews\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d62aee65-d4c6-4511-af5e-12ee7c801e92"
        },
        "id": "7o4vmbXR0W0P",
        "outputId": "8de91240-f36c-45fe-e135-52a383092ec3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+--------------------+-----+\n|              Review|Liked|\n+--------------------+-----+\n|Wow... Loved this...|    1|\n|  Crust is not good.|    0|\n|Not tasty and the...|    0|\n|Stopped by during...|    1|\n|The selection on ...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n              Review|Liked|\n+--------------------+-----+\nWow... Loved this...|    1|\n  Crust is not good.|    0|\nNot tasty and the...|    0|\nStopped by during...|    1|\nThe selection on ...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4aad3a6e-8155-4b83-8487-0e400876a9cb"
        },
        "id": "KOgYrXiX0W0P",
        "outputId": "20cbacef-0563-4930-f9e5-8d47aa9439b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">root\n |-- Review: string (nullable = true)\n |-- Liked: integer (nullable = true)\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Review: string (nullable = true)\n-- Liked: integer (nullable = true)\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "47576194-85ed-4243-b202-9665c01d295e"
        },
        "id": "XJhqrjLw0W0P",
        "outputId": "0fc64d30-c447-46cf-d167-1fd01b17e0dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[4]: 1000</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: 1000</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "Splitting of sentences into individual words for processing"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9e27d7a2-bacc-41fd-a066-16623f949d0e"
        },
        "id": "NRFXaOot0W0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import udf"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "329e765d-c8ae-431a-aa10-d21bca5658e2"
        },
        "id": "VQH1E6fR0W0Q",
        "outputId": "48ebdefb-360c-4a59-ce4b-f4960cfe2360"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol='Review', outputCol='words') # Splits sentences into whole words\n",
        "\n",
        "regexTokenizer = RegexTokenizer(inputCol='Review', outputCol='words', pattern='\\\\W') # Splits sentences into whole words, ignores punctuation\n",
        "\n",
        "countTokens = udf(lambda p: len(p), IntegerType()) # udf applies the lambda function to each row when called on a column"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fe2bff80-6839-4d29-bf84-7a4d2e52905d"
        },
        "id": "XpGqpLr90W0S",
        "outputId": "637fac02-393f-4750-97aa-8bb0c05c3be1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.transform(df)\n",
        "tokenized.withColumn('tokens', countTokens(col('words'))).show()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "406316a9-3494-4208-9a5e-ac0f086ef819"
        },
        "id": "kGgJRi600W0S",
        "outputId": "aeba8be6-e859-4f90-c9be-54bfe1f24bc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+--------------------+-----+--------------------+------+\n|              Review|Liked|               words|tokens|\n+--------------------+-----+--------------------+------+\n|Wow... Loved this...|    1|[wow..., loved, t...|     4|\n|  Crust is not good.|    0|[crust, is, not, ...|     4|\n|Not tasty and the...|    0|[not, tasty, and,...|     8|\n|Stopped by during...|    1|[stopped, by, dur...|    15|\n|The selection on ...|    1|[the, selection, ...|    12|\n|Now I am getting ...|    0|[now, i, am, gett...|    11|\n|Honeslty it didn&#39;...|    0|[honeslty, it, di...|     6|\n|The potatoes were...|    0|[the, potatoes, w...|    22|\n|The fries were gr...|    1|[the, fries, were...|     5|\n|      A great touch.|    1|  [a, great, touch.]|     3|\n|Service was very ...|    1|[service, was, ve...|     4|\n|  Would not go back.|    0|[would, not, go, ...|     4|\n|The cashier had n...|    0|[the, cashier, ha...|    21|\n|I tried the Cape ...|    1|[i, tried, the, c...|     9|\n|I was disgusted b...|    0|[i, was, disguste...|    12|\n|I was shocked bec...|    0|[i, was, shocked,...|     9|\n| Highly recommended.|    1|[highly, recommen...|     2|\n|Waitress was a li...|    0|[waitress, was, a...|     7|\n|This place is not...|    0|[this, place, is,...|    10|\n|did not like at all.|    0|[did, not, like, ...|     5|\n+--------------------+-----+--------------------+------+\nonly showing top 20 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+--------------------+------+\n              Review|Liked|               words|tokens|\n+--------------------+-----+--------------------+------+\nWow... Loved this...|    1|[wow..., loved, t...|     4|\n  Crust is not good.|    0|[crust, is, not, ...|     4|\nNot tasty and the...|    0|[not, tasty, and,...|     8|\nStopped by during...|    1|[stopped, by, dur...|    15|\nThe selection on ...|    1|[the, selection, ...|    12|\nNow I am getting ...|    0|[now, i, am, gett...|    11|\nHoneslty it didn&#39;...|    0|[honeslty, it, di...|     6|\nThe potatoes were...|    0|[the, potatoes, w...|    22|\nThe fries were gr...|    1|[the, fries, were...|     5|\n      A great touch.|    1|  [a, great, touch.]|     3|\nService was very ...|    1|[service, was, ve...|     4|\n  Would not go back.|    0|[would, not, go, ...|     4|\nThe cashier had n...|    0|[the, cashier, ha...|    21|\nI tried the Cape ...|    1|[i, tried, the, c...|     9|\nI was disgusted b...|    0|[i, was, disguste...|    12|\nI was shocked bec...|    0|[i, was, shocked,...|     9|\n Highly recommended.|    1|[highly, recommen...|     2|\nWaitress was a li...|    0|[waitress, was, a...|     7|\nThis place is not...|    0|[this, place, is,...|    10|\ndid not like at all.|    0|[did, not, like, ...|     5|\n+--------------------+-----+--------------------+------+\nonly showing top 20 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Word Removal\n",
        "\n",
        "Removal of common words which add little to no meaning to the sentence"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f266a4de-0287-4d53-bcd1-3ec20ceac622"
        },
        "id": "B1vc4ijP0W0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b41e12a4-ffcc-4c31-9b02-984bc476e553"
        },
        "id": "ZTARe8DX0W0U",
        "outputId": "e84ec2e6-9338-4648-aec7-42e913f8f1b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5, truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b72eeb82-119e-47c8-8ea0-5192f5edf45d"
        },
        "id": "uq9Vlzsi0W0U",
        "outputId": "3d3e0800-dd7a-476f-8b46-cbaa8674db58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+---------------------------------------------------------------------------------------+-----+\n|Review                                                                                 |Liked|\n+---------------------------------------------------------------------------------------+-----+\n|Wow... Loved this place.                                                               |1    |\n|Crust is not good.                                                                     |0    |\n|Not tasty and the texture was just nasty.                                              |0    |\n|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.|1    |\n|The selection on the menu was great and so were the prices.                            |1    |\n+---------------------------------------------------------------------------------------+-----+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------+-----+\nReview                                                                                 |Liked|\n+---------------------------------------------------------------------------------------+-----+\nWow... Loved this place.                                                               |1    |\nCrust is not good.                                                                     |0    |\nNot tasty and the texture was just nasty.                                              |0    |\nStopped by during the late May bank holiday off Rick Steve recommendation and loved it.|1    |\nThe selection on the menu was great and so were the prices.                            |1    |\n+---------------------------------------------------------------------------------------+-----+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "remover = StopWordsRemover(inputCol='words', outputCol='cleaned')\n",
        "remover.transform(tokenized).select('cleaned').show(5, truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "490c7051-169d-4826-bade-0db526c0c6f5"
        },
        "id": "6mb15YUb0W0V",
        "outputId": "a1c3d25f-2751-42e0-b814-1a73343d8e86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+----------------------------------------------------------------------------+\n|cleaned                                                                     |\n+----------------------------------------------------------------------------+\n|[wow..., loved, place.]                                                     |\n|[crust, good.]                                                              |\n|[tasty, texture, nasty.]                                                    |\n|[stopped, late, may, bank, holiday, rick, steve, recommendation, loved, it.]|\n|[selection, menu, great, prices.]                                           |\n+----------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------+\ncleaned                                                                     |\n+----------------------------------------------------------------------------+\n[wow..., loved, place.]                                                     |\n[crust, good.]                                                              |\n[tasty, texture, nasty.]                                                    |\n[stopped, late, may, bank, holiday, rick, steve, recommendation, loved, it.]|\n[selection, menu, great, prices.]                                           |\n+----------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## n-grams"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "16d14c18-bc12-4a2f-b0d5-4706914a38f6"
        },
        "id": "qA8xUlcU0W0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import NGram"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "870bbaa0-8590-43db-9c9a-c5d44beeb04d"
        },
        "id": "0gZOzCAT0W0V",
        "outputId": "e835fd76-87a3-45a3-963b-22a33b1edf09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = NGram(n=2, inputCol='words', outputCol='bigrams')\n",
        "bigram_df = bigram.transform(tokenized).select('bigrams').show(5, truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "261d7ba2-6024-4000-8f1c-f60e4dd0295f"
        },
        "id": "KbDGMmdC0W0W",
        "outputId": "3241a71b-468e-4c5b-80d4-bb386d6b20ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|bigrams                                                                                                                                                                           |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[wow... loved, loved this, this place.]                                                                                                                                           |\n|[crust is, is not, not good.]                                                                                                                                                     |\n|[not tasty, tasty and, and the, the texture, texture was, was just, just nasty.]                                                                                                  |\n|[stopped by, by during, during the, the late, late may, may bank, bank holiday, holiday off, off rick, rick steve, steve recommendation, recommendation and, and loved, loved it.]|\n|[the selection, selection on, on the, the menu, menu was, was great, great and, and so, so were, were the, the prices.]                                                           |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nbigrams                                                                                                                                                                           |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n[wow... loved, loved this, this place.]                                                                                                                                           |\n[crust is, is not, not good.]                                                                                                                                                     |\n[not tasty, tasty and, and the, the texture, texture was, was just, just nasty.]                                                                                                  |\n[stopped by, by during, during the, the late, late may, may bank, bank holiday, holiday off, off rick, rick steve, steve recommendation, recommendation and, and loved, loved it.]|\n[the selection, selection on, on the, the menu, menu was, was great, great and, and so, so were, were the, the prices.]                                                           |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Term Freq; Inverse Doc Freq (TF-IDF)\n",
        "Importance of specific words. Generally, the more a word is used, the less unique meaning it carries within a corpus. Thus, inverse frequency is used."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "33deb379-51e0-429a-8ae9-710f0844275e"
        },
        "id": "FF_GN7_N0W0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ab4ad4fb-d7a8-4f94-8800-a965ba28b4e5"
        },
        "id": "44-TfZHt0W0W",
        "outputId": "f7094f81-e111-4730-a195-bfdffa44b134"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexTokenizer(inputCol='Review', outputCol='words', pattern='\\\\W')\n",
        "words = tokenizer.transform(df)\n",
        "words.show(5, truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e60f6d66-0619-4be2-8e62-ce6dba55f88b"
        },
        "id": "biJGXGfy0W0X",
        "outputId": "5022f2e6-ca6b-4187-b3f8-426c21816858"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\n|Review                                                                                 |Liked|words                                                                                                 |\n+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\n|Wow... Loved this place.                                                               |1    |[wow, loved, this, place]                                                                             |\n|Crust is not good.                                                                     |0    |[crust, is, not, good]                                                                                |\n|Not tasty and the texture was just nasty.                                              |0    |[not, tasty, and, the, texture, was, just, nasty]                                                     |\n|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.|1    |[stopped, by, during, the, late, may, bank, holiday, off, rick, steve, recommendation, and, loved, it]|\n|The selection on the menu was great and so were the prices.                            |1    |[the, selection, on, the, menu, was, great, and, so, were, the, prices]                               |\n+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\nReview                                                                                 |Liked|words                                                                                                 |\n+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\nWow... Loved this place.                                                               |1    |[wow, loved, this, place]                                                                             |\nCrust is not good.                                                                     |0    |[crust, is, not, good]                                                                                |\nNot tasty and the texture was just nasty.                                              |0    |[not, tasty, and, the, texture, was, just, nasty]                                                     |\nStopped by during the late May bank holiday off Rick Steve recommendation and loved it.|1    |[stopped, by, during, the, late, may, bank, holiday, off, rick, steve, recommendation, and, loved, it]|\nThe selection on the menu was great and so were the prices.                            |1    |[the, selection, on, the, menu, was, great, and, so, were, the, prices]                               |\n+---------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=20)\n",
        "featurized = hashingTF.transform(words)\n",
        "featurized.show(5)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c5573d25-ac92-4cbd-aea5-5e5b67601fce"
        },
        "id": "yN1HHjem0W0X",
        "outputId": "eefae5d9-d2c0-4503-d0c6-0c75a83aaef3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+--------------------+-----+--------------------+--------------------+\n|              Review|Liked|               words|         rawFeatures|\n+--------------------+-----+--------------------+--------------------+\n|Wow... Loved this...|    1|[wow, loved, this...|(20,[9,10,13,19],...|\n|  Crust is not good.|    0|[crust, is, not, ...|(20,[5,8,9,18],[1...|\n|Not tasty and the...|    0|[not, tasty, and,...|(20,[2,3,4,5,7,11...|\n|Stopped by during...|    1|[stopped, by, dur...|(20,[0,1,2,3,4,6,...|\n|The selection on ...|    1|[the, selection, ...|(20,[2,3,10,11,16...|\n+--------------------+-----+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+--------------------+--------------------+\n              Review|Liked|               words|         rawFeatures|\n+--------------------+-----+--------------------+--------------------+\nWow... Loved this...|    1|[wow, loved, this...|(20,[9,10,13,19],...|\n  Crust is not good.|    0|[crust, is, not, ...|(20,[5,8,9,18],[1...|\nNot tasty and the...|    0|[not, tasty, and,...|(20,[2,3,4,5,7,11...|\nStopped by during...|    1|[stopped, by, dur...|(20,[0,1,2,3,4,6,...|\nThe selection on ...|    1|[the, selection, ...|(20,[2,3,10,11,16...|\n+--------------------+-----+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
        "idf_model = idf.fit(featurized)\n",
        "rescale = idf_model.transform(featurized)\n",
        "rescale.select('Liked', 'features').show(5)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "a39564cd-bfd8-42be-a07d-9915b77149e6"
        },
        "id": "TR0dr-pE0W0X",
        "outputId": "57506ca4-887d-4cd3-b2a8-a00b1a921f01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+-----+--------------------+\n|Liked|            features|\n+-----+--------------------+\n|    1|(20,[9,10,13,19],...|\n|    0|(20,[5,8,9,18],[1...|\n|    0|(20,[2,3,4,5,7,11...|\n|    1|(20,[0,1,2,3,4,6,...|\n|    1|(20,[2,3,10,11,16...|\n+-----+--------------------+\nonly showing top 5 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nLiked|            features|\n+-----+--------------------+\n    1|(20,[9,10,13,19],...|\n    0|(20,[5,8,9,18],[1...|\n    0|(20,[2,3,4,5,7,11...|\n    1|(20,[0,1,2,3,4,6,...|\n    1|(20,[2,3,10,11,16...|\n+-----+--------------------+\nonly showing top 5 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prototype Model\n",
        "From what I understand, NLP follows the following 'simple' procedure:\n",
        "1) Process text data\n",
        "2) Make features numeric (i.e. vectorization)\n",
        "3) Train using existing ML models (such as random forest classifier)\n",
        "\n",
        "In my research the 'sparknlp' library provides access to more refined tools for NLP tasks, and so now I will be working with that. My original dataframe from above is still intact, I will be starting there."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "466c444d-4029-4817-b648-8ead24e3f01e"
        },
        "id": "KO9xikPc0W0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import * # Change once all used modules are known\n",
        "from sparknlp.annotator import * # Change once all used modules are known\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, DecisionTreeClassifier, LinearSVC, LogisticRegression\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "eac0a750-3b6a-4cc0-8396-1a157baddba7"
        },
        "id": "9z_OFMn10W0Y",
        "outputId": "e111d866-9427-4482-ff5b-2ec05b597e71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "46c0cd30-5b26-4be1-a9cc-d8b0531e079d"
        },
        "id": "c2ef99Cp0W0Y",
        "outputId": "225afb7a-38f8-4294-f97f-056a9cb9f36d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotation\n",
        "\n",
        "The text needs to be formatted and cleaned as much as possible prior to the vectorization of the data. The steps I wish to implement, to some degree, are as follows. For all of these points, I will modify my approach as new information becomes available to me.\n",
        "1) **Tokenization**\n",
        "    * Splitting of reviews into individual words. This may or may not involve multiple steps, a custom RegEx, or more.\n",
        "2) **Spell-checking**\n",
        "    * All words should be spell-checked prior to any future steps for obvious reasons.\n",
        "3) **Stop-words**\n",
        "    * Removal of unnecessary words that do not contribute significant meaning to the sentence. Removal of these words places more emphasis on the words that matter during training.\n",
        "4) **Lemmatization**\n",
        "    * Words should be reduced to their lemma forms in order to make the text more readable to the computer (i.e. Doing, Does, Did -> Do). In theory, this should strengthen the patterns between certain words and their corresponding meaning as interpreted by the algorithm."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4e59459c-00cb-4fc6-a662-39a9d9b6bb4f"
        },
        "id": "ZZnfrh5U0W0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = DocumentAssembler()\\\n",
        "                .setInputCol('Review')\\\n",
        "                .setOutputCol('document')\\\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "                .setInputCols('document')\\\n",
        "                .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "                .setInputCols('sentence')\\\n",
        "                .setOutputCol('token')\n",
        "\n",
        "checker = NorvigSweetingModel()\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols('token')\\\n",
        "                .setOutputCol('checked')\n",
        "\n",
        "stopwords = StopWordsCleaner()\\\n",
        "                .pretrained('stopwords_en', 'en')\\\n",
        "                .setInputCols('checked')\\\n",
        "                .setOutputCol('cleaned')\n",
        "\n",
        "lemmatizer = LemmatizerModel()\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols('cleaned')\\\n",
        "                .setOutputCol('lemma')"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "3aafb554-6e19-4598-9896-2a0c156be897"
        },
        "id": "pGk7bWi40W0Z",
        "outputId": "f80e348e-3442-479f-f906-7bdd723bf21d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">spellcheck_norvig download started this may take some time.\nApproximate size to download 4.2 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[OK!]\nstopwords_en download started this may take some time.\nApproximate size to download 2.9 KB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[OK!]\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">spellcheck_norvig download started this may take some time.\nApproximate size to download 4.2 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[OK!]\nstopwords_en download started this may take some time.\nApproximate size to download 2.9 KB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[OK!]\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline().setStages([document, sentence, tokenizer, checker, stopwords, lemmatizer])\n",
        "model = pipeline.fit(df)\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "aace005f-62bc-42c9-b13a-06604805385d"
        },
        "id": "xcBNFLwZ0W0a",
        "outputId": "f8cd412a-5fa2-432c-d514-7cfce2e4cfbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result.select('Review', 'lemma.result').show(truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ea9a69da-235c-4fb8-b0b6-52167785ac36"
        },
        "id": "KIRb3DLy0W0a",
        "outputId": "3e6b3e00-b9fc-4bef-a80f-d4fa6ddccfc0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\n|Review                                                                                                         |result                                                              |\n+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\n|Wow... Loved this place.                                                                                       |[Wow, ..., move, place, .]                                          |\n|Crust is not good.                                                                                             |[Crust, good, .]                                                    |\n|Not tasty and the texture was just nasty.                                                                      |[tasty, texture, nasty, .]                                          |\n|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |[Stopped, late, bank, holiday, Rick, Steve, recommendation, love, .]|\n|The selection on the menu was great and so were the prices.                                                    |[selection, menu, great, price, .]                                  |\n|Now I am getting angry and I want my damn pho.                                                                 |[angry, damn, pho, .]                                               |\n|Honeslty it didn&#39;t taste THAT fresh.)                                                                          |[Honestly, taste, fresh, ., )]                                      |\n|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|[potato, rubber, make, ahead, time, warm, .]                        |\n|The fries were great too.                                                                                      |[fry, great, .]                                                     |\n|A great touch.                                                                                                 |[great, touch, .]                                                   |\n|Service was very prompt.                                                                                       |[Service, prompt, .]                                                |\n|Would not go back.                                                                                             |[back, .]                                                           |\n|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |[cashier, care, end, overpriced, .]                                 |\n|I tried the Cape Cod ravoli, chicken, with cranberry...mmmm!                                                   |[Cape, Cod, ravioli, ,, chicken, ,, cranberry, ., ., ., mmm, !]     |\n|I was disgusted because I was pretty sure that was human hair.                                                 |[disgust, pretty, human, hair, .]                                   |\n|I was shocked because no signs indicate cash only.                                                             |[shock, sign, cash, .]                                              |\n|Highly recommended.                                                                                            |[Highly, recommend, .]                                              |\n|Waitress was a little slow in service.                                                                         |[waitress, slow, service, .]                                        |\n|This place is not worth your time, let alone Vegas.                                                            |[place, worth, time, ,, Vegas, .]                                   |\n|did not like at all.                                                                                           |[.]                                                                 |\n+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\nReview                                                                                                         |result                                                              |\n+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\nWow... Loved this place.                                                                                       |[Wow, ..., move, place, .]                                          |\nCrust is not good.                                                                                             |[Crust, good, .]                                                    |\nNot tasty and the texture was just nasty.                                                                      |[tasty, texture, nasty, .]                                          |\nStopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |[Stopped, late, bank, holiday, Rick, Steve, recommendation, love, .]|\nThe selection on the menu was great and so were the prices.                                                    |[selection, menu, great, price, .]                                  |\nNow I am getting angry and I want my damn pho.                                                                 |[angry, damn, pho, .]                                               |\nHoneslty it didn&#39;t taste THAT fresh.)                                                                          |[Honestly, taste, fresh, ., )]                                      |\nThe potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|[potato, rubber, make, ahead, time, warm, .]                        |\nThe fries were great too.                                                                                      |[fry, great, .]                                                     |\nA great touch.                                                                                                 |[great, touch, .]                                                   |\nService was very prompt.                                                                                       |[Service, prompt, .]                                                |\nWould not go back.                                                                                             |[back, .]                                                           |\nThe cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |[cashier, care, end, overpriced, .]                                 |\nI tried the Cape Cod ravoli, chicken, with cranberry...mmmm!                                                   |[Cape, Cod, ravioli, ,, chicken, ,, cranberry, ., ., ., mmm, !]     |\nI was disgusted because I was pretty sure that was human hair.                                                 |[disgust, pretty, human, hair, .]                                   |\nI was shocked because no signs indicate cash only.                                                             |[shock, sign, cash, .]                                              |\nHighly recommended.                                                                                            |[Highly, recommend, .]                                              |\nWaitress was a little slow in service.                                                                         |[waitress, slow, service, .]                                        |\nThis place is not worth your time, let alone Vegas.                                                            |[place, worth, time, ,, Vegas, .]                                   |\ndid not like at all.                                                                                           |[.]                                                                 |\n+---------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an issue with the first line spell checking 'Loved' to 'moved' and eventually lemmatized to 'move'. Perhaps a different tokenizer without punctuation would help. Important negators like 'not' are being flagged by the stopwords filter, and this is a big problem. A review like 'Crust is not good' being turned into 'Crust good' is clearly a flipping of the sentiment of the review. I will need to look into this.\n",
        "\n",
        "I want to create a custom RegEx that will exclude almost all punctuation except for apostrophes and hyphens. As I have zero experience with RegEx, I found a website that allows me to test different RegEx expressions and see how they affect sample text. Using this, I was able to create the RegEx expression r\"[a-zA-Z0-9\\'\\-]\" which should include everything I need, and exclude the rest. Since this is being applied after a sentencer, I do not need to worry about single periods."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "26d33208-3215-4add-970c-28273de5a740"
        },
        "id": "2DzyfPq-0W0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexTokenizer()\\\n",
        "                .setInputCols('sentence')\\\n",
        "                .setOutputCol('token')\\\n",
        "                .setPattern(r'[^a-zA-Z0-9_\\']')\n",
        "\n",
        "checker = ContextSpellCheckerModel\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols(\"token\")\\\n",
        "                .setOutputCol(\"checked\")\n",
        "\n",
        "lemmatizer = LemmatizerModel()\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols('checked')\\\n",
        "                .setOutputCol('lemma')\n",
        "\n",
        "stopwords = StopWordsCleaner()\\\n",
        "                .pretrained('stopwords_iso', 'en')\\\n",
        "                .setInputCols('lemma')\\\n",
        "                .setOutputCol('cleaned')\n",
        "\n",
        "finisher = Finisher()\\\n",
        "                .setInputCols('lemma')\\\n",
        "                .setOutputCols('result')"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "393212c4-2287-4cc9-8255-552f74655216"
        },
        "id": "2VB7S9oJ0W0b",
        "outputId": "c98b0e43-8470-49e8-f5ed-56c68a6a6630"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\nstopwords_iso download started this may take some time.\nApproximate size to download 2.1 KB\n\r[ | ]\r[OK!]\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\nstopwords_iso download started this may take some time.\nApproximate size to download 2.1 KB\n\r[ | ]\r[OK!]\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline().setStages([document, sentence, tokenizer, checker, lemmatizer, finisher])\n",
        "model = pipeline.fit(df)\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "58ba8f01-862e-40ad-94e0-570fcd73edd6"
        },
        "id": "gtBNCwhd0W0c",
        "outputId": "77e2ec91-8895-4457-ad1b-829a13f94b42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result.show(truncate=False)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "7746824c-5d8f-456e-b16f-9b3712fdccf8"
        },
        "id": "y85Z71vK0W0c",
        "outputId": "20d454a7-c1bf-487a-8a14-1d7d545f3434"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n|Review                                                                                                         |Liked|finished                                                                                                                   |cleaned                                                                        |rawFeatures                                                                                                                                               |features                                                                                                                                                                                                                                                                                                                                                                                                                                                  |label|\n+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n|Wow... Loved this place.                                                                                       |1    |[Wow, Loved, this, place]                                                                                                  |[Wow, Loved, place]                                                            |(1935,[10,17,810,839],[1.0,1.0,1.0,1.0])                                                                                                                  |(1935,[10,17,810,839],[2.226623552191001,2.4089451089849554,5.810142490647111,5.810142490647111])                                                                                                                                                                                                                                                                                                                                                         |1    |\n|Crust is not good.                                                                                             |0    |[Crust, be, not, good]                                                                                                     |[Crust, not, good]                                                             |(1935,[0,11,14,1239],[1.0,1.0,1.0,1.0])                                                                                                                   |(1935,[0,11,14,1239],[0.5754751511755302,2.235925944853314,2.2837819660309497,6.215607598755275])                                                                                                                                                                                                                                                                                                                                                         |0    |\n|Not tasty and the texture was just nasty.                                                                      |0    |[Not, tasty, and, the, texture, be, just, nasty]                                                                           |[Not, tasty, texture, just, nasty]                                             |(1935,[0,1,2,43,156,171,482,875],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                       |(1935,[0,1,2,43,156,171,482,875],[0.5754751511755302,1.1066364039381575,1.1096621248546947,3.443018876515494,4.4238481295272205,4.51085950651685,5.52246041819533,5.810142490647111])                                                                                                                                                                                                                                                                     |0    |\n|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |1    |[Stopped, by, during, the, late, May, bank, holiday, off, Rick, Steve, recommendation, and, love, it]                      |[Stopped, late, May, bank, Rick, Steve, recommendation, love]                  |(1935,[1,2,12,58,93,180,237,344,559,702,981,1130,1441,1917,1918],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |(1935,[1,2,12,58,93,180,237,344,559,702,981,1130,1441,1917,1918],[1.1066364039381575,1.1096621248546947,2.3237873006446486,3.6506582412937387,3.96431580014878,4.6061696863211745,4.829313237635384,5.116995310087166,5.52246041819533,5.810142490647111,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                      |1    |\n|The selection on the menu was great and so were the prices.                                                    |1    |[The, selection, on, the, menu, be, great, and, so, be, the, price]                                                        |[selection, menu, great, price]                                                |(1935,[0,1,2,6,27,32,34,84,106,144],[2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                            |(1935,[0,1,2,6,27,32,34,84,106,144],[1.1509503023510603,2.213272807876315,1.1096621248546947,1.7213689734744655,2.831217335409501,3.0375537684073297,3.016934481204594,3.8642323415917974,4.075541435259004,4.4238481295272205])                                                                                                                                                                                                                          |1    |\n|Now I am getting angry and I want my damn pho.                                                                 |0    |[Now, I, be, get, angry, and, I, want, i, damn, Rho]                                                                       |[angry, damn, Rho]                                                             |(1935,[0,2,3,18,35,103,375,443,1274,1933],[1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                      |(1935,[0,2,3,18,35,103,375,443,1274,1933],[0.5754751511755302,1.1096621248546947,2.734982468313589,2.5143056246427817,3.102092289544901,4.075541435259004,5.29931686688112,5.52246041819533,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                         |0    |\n|Honeslty it didn&#39;t taste THAT fresh.)                                                                          |0    |[Honesty, it, didn&#39;t, taste, THAT, fresh]                                                                                  |[didn&#39;t, taste, fresh]                                                         |(1935,[12,77,126,135,1149,1457],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                |(1935,[12,77,126,135,1149,1457],[2.3237873006446486,3.8642323415917974,4.200704578213011,4.269697449699962,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                                                                                                          |0    |\n|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|0    |[The, potato, be, like, rubber, and, you, could, tell, they, have, be, make, up, ahead, of, time, be, keep, under, a, warm]|[potato, like, rubber, could, tell, have, make, ahead, time, keep, under, warm]|(1935,[0,2,4,6,7,8,19,20,30,33,55,56,108,195,221,226,333,481,1237,1634],[3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(1935,[0,2,4,6,7,8,19,20,30,33,55,56,108,195,221,226,333,481,1237,1634],[1.7264254535265904,1.1096621248546947,1.6357552207514738,1.7213689734744655,2.0109149793643093,2.104733734581964,2.7343675094195836,2.6602595372658615,2.938462865763099,2.9967317738870745,3.6129179133108917,3.68987895444702,4.075541435259004,4.6061696863211745,4.711530201979001,4.711530201979001,5.116995310087166,5.52246041819533,6.215607598755275,6.215607598755275])|0    |\n|The fries were great too.                                                                                      |1    |[The, fry, be, great, too]                                                                                                 |[fry, great, too]                                                              |(1935,[0,6,32,109,122],[1.0,1.0,1.0,1.0,1.0])                                                                                                             |(1935,[0,6,32,109,122],[0.5754751511755302,1.7213689734744655,3.0375537684073297,4.13616605707544,4.13616605707544])                                                                                                                                                                                                                                                                                                                                      |1    |\n|A great touch.                                                                                                 |1    |[A, great, touch]                                                                                                          |[great, touch]                                                                 |(1935,[32,190,570],[1.0,1.0,1.0])                                                                                                                         |(1935,[32,190,570],[3.0375537684073297,4.711530201979001,5.52246041819533])                                                                                                                                                                                                                                                                                                                                                                               |1    |\n|Service was very prompt.                                                                                       |1    |[Service, be, very, prompt]                                                                                                |[Service, very, prompt]                                                        |(1935,[0,25,115,1228],[1.0,1.0,1.0,1.0])                                                                                                                  |(1935,[0,25,115,1228],[0.5754751511755302,2.831217335409501,4.075541435259004,6.215607598755275])                                                                                                                                                                                                                                                                                                                                                         |1    |\n|Would not go back.                                                                                             |0    |[Would, not, go, back]                                                                                                     |[Would, not, go]                                                               |(1935,[14,21,26,464],[1.0,1.0,1.0,1.0])                                                                                                                   |(1935,[14,21,26,464],[2.2837819660309497,2.6046896861110507,2.81441021709312,5.52246041819533])                                                                                                                                                                                                                                                                                                                                                           |0    |\n|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |0    |[The, Fasher, have, no, care, what, so, ever, on, what, I, have, to, say, it, still, end, up, be, way, override]           |[Fasher, have, no, care, ever, have, override]                                 |(1935,[0,3,5,6,7,12,27,34,51,56,57,82,95,111,149,304,314,366,1847],[1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])         |(1935,[0,3,5,6,7,12,27,34,51,56,57,82,95,111,149,304,314,366,1847],[0.5754751511755302,1.3674912341567944,1.7157979284250102,1.7213689734744655,4.021829958728619,2.3237873006446486,2.831217335409501,3.016934481204594,3.6129179133108917,3.68987895444702,3.6506582412937387,3.9130225057612296,4.018383021419056,8.27233211415088,4.4238481295272205,5.116995310087166,5.116995310087166,5.29931686688112,6.215607598755275])                         |0    |\n|I tried the Cape Cod ravoli, chicken, with cranberry...mmmm!                                                   |1    |[I, try, the, Cape, Cod, revolt, chicken, with, Cranberry, mmHg]                                                           |[try, Cape, Cod, revolt, chicken, with, Cranberry, mmHg]                       |(1935,[1,3,22,112,117,927,1342,1488,1620,1890],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                 |(1935,[1,3,22,112,117,927,1342,1488,1620,1890],[1.1066364039381575,1.3674912341567944,2.674648274717961,4.269697449699962,4.13616605707544,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                    |1    |\n|I was disgusted because I was pretty sure that was human hair.                                                 |0    |[I, be, disgust, because, I, be, pretty, sure, that, be, human, hair]                                                      |[disgust, pretty, sure, human, hair]                                           |(1935,[0,3,24,97,124,219,737,741,864],[3.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                              |(1935,[0,3,24,97,124,219,737,741,864],[1.7264254535265904,2.734982468313589,2.765620052923688,4.075541435259004,4.200704578213011,4.711530201979001,5.810142490647111,5.810142490647111,5.810142490647111])                                                                                                                                                                                                                                               |0    |\n|I was shocked because no signs indicate cash only.                                                             |0    |[I, be, shock, because, no, sign, indicate, cash, only]                                                                    |[shock, no, sign, indicate, cash, only]                                        |(1935,[0,3,59,82,124,819,932,960,1202],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                             |(1935,[0,3,59,82,124,819,932,960,1202],[0.5754751511755302,1.3674912341567944,3.6506582412937387,3.9130225057612296,4.200704578213011,5.810142490647111,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                                           |0    |\n|Highly recommended.                                                                                            |1    |[Highly, recommend]                                                                                                        |[Highly, recommend]                                                            |(1935,[118,589],[1.0,1.0])                                                                                                                                |(1935,[118,589],[4.13616605707544,5.810142490647111])                                                                                                                                                                                                                                                                                                                                                                                                     |1    |\n|Waitress was a little slow in service.                                                                         |0    |[Waitress, be, a, little, slow, in, service]                                                                               |[Waitress, slow, service]                                                      |(1935,[0,4,15,23,153,158,516],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                              |(1935,[0,4,15,23,153,158,516],[0.5754751511755302,1.6357552207514738,2.3237873006446486,2.6320886602991656,4.51085950651685,4.51085950651685,5.52246041819533])                                                                                                                                                                                                                                                                                           |0    |\n|This place is not worth your time, let alone Vegas.                                                            |0    |[This, place, be, not, worth, you, time, let, alone, Vegas]                                                                |[place, not, worth, time, Vegas]                                               |(1935,[0,10,14,19,30,36,72,157,565,1250],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                       |(1935,[0,10,14,19,30,36,72,157,565,1250],[0.5754751511755302,2.226623552191001,2.2837819660309497,2.7343675094195836,2.938462865763099,3.058607177605162,3.7732605633860707,4.51085950651685,5.52246041819533,6.215607598755275])                                                                                                                                                                                                                         |0    |\n|did not like at all.                                                                                           |0    |[do, not, like, at, all]                                                                                                   |[do, not, like]                                                                |(1935,[14,31,33,37,39],[1.0,1.0,1.0,1.0,1.0])                                                                                                             |(1935,[14,31,33,37,39],[2.2837819660309497,2.938462865763099,2.9967317738870745,3.245193133185574,3.353406717825807])                                                                                                                                                                                                                                                                                                                                     |0    |\n+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\nonly showing top 20 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\nReview                                                                                                         |Liked|finished                                                                                                                   |cleaned                                                                        |rawFeatures                                                                                                                                               |features                                                                                                                                                                                                                                                                                                                                                                                                                                                  |label|\n+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\nWow... Loved this place.                                                                                       |1    |[Wow, Loved, this, place]                                                                                                  |[Wow, Loved, place]                                                            |(1935,[10,17,810,839],[1.0,1.0,1.0,1.0])                                                                                                                  |(1935,[10,17,810,839],[2.226623552191001,2.4089451089849554,5.810142490647111,5.810142490647111])                                                                                                                                                                                                                                                                                                                                                         |1    |\nCrust is not good.                                                                                             |0    |[Crust, be, not, good]                                                                                                     |[Crust, not, good]                                                             |(1935,[0,11,14,1239],[1.0,1.0,1.0,1.0])                                                                                                                   |(1935,[0,11,14,1239],[0.5754751511755302,2.235925944853314,2.2837819660309497,6.215607598755275])                                                                                                                                                                                                                                                                                                                                                         |0    |\nNot tasty and the texture was just nasty.                                                                      |0    |[Not, tasty, and, the, texture, be, just, nasty]                                                                           |[Not, tasty, texture, just, nasty]                                             |(1935,[0,1,2,43,156,171,482,875],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                       |(1935,[0,1,2,43,156,171,482,875],[0.5754751511755302,1.1066364039381575,1.1096621248546947,3.443018876515494,4.4238481295272205,4.51085950651685,5.52246041819533,5.810142490647111])                                                                                                                                                                                                                                                                     |0    |\nStopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |1    |[Stopped, by, during, the, late, May, bank, holiday, off, Rick, Steve, recommendation, and, love, it]                      |[Stopped, late, May, bank, Rick, Steve, recommendation, love]                  |(1935,[1,2,12,58,93,180,237,344,559,702,981,1130,1441,1917,1918],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |(1935,[1,2,12,58,93,180,237,344,559,702,981,1130,1441,1917,1918],[1.1066364039381575,1.1096621248546947,2.3237873006446486,3.6506582412937387,3.96431580014878,4.6061696863211745,4.829313237635384,5.116995310087166,5.52246041819533,5.810142490647111,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                      |1    |\nThe selection on the menu was great and so were the prices.                                                    |1    |[The, selection, on, the, menu, be, great, and, so, be, the, price]                                                        |[selection, menu, great, price]                                                |(1935,[0,1,2,6,27,32,34,84,106,144],[2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                            |(1935,[0,1,2,6,27,32,34,84,106,144],[1.1509503023510603,2.213272807876315,1.1096621248546947,1.7213689734744655,2.831217335409501,3.0375537684073297,3.016934481204594,3.8642323415917974,4.075541435259004,4.4238481295272205])                                                                                                                                                                                                                          |1    |\nNow I am getting angry and I want my damn pho.                                                                 |0    |[Now, I, be, get, angry, and, I, want, i, damn, Rho]                                                                       |[angry, damn, Rho]                                                             |(1935,[0,2,3,18,35,103,375,443,1274,1933],[1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                      |(1935,[0,2,3,18,35,103,375,443,1274,1933],[0.5754751511755302,1.1096621248546947,2.734982468313589,2.5143056246427817,3.102092289544901,4.075541435259004,5.29931686688112,5.52246041819533,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                         |0    |\nHoneslty it didn&#39;t taste THAT fresh.)                                                                          |0    |[Honesty, it, didn&#39;t, taste, THAT, fresh]                                                                                  |[didn&#39;t, taste, fresh]                                                         |(1935,[12,77,126,135,1149,1457],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                |(1935,[12,77,126,135,1149,1457],[2.3237873006446486,3.8642323415917974,4.200704578213011,4.269697449699962,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                                                                                                          |0    |\nThe potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|0    |[The, potato, be, like, rubber, and, you, could, tell, they, have, be, make, up, ahead, of, time, be, keep, under, a, warm]|[potato, like, rubber, could, tell, have, make, ahead, time, keep, under, warm]|(1935,[0,2,4,6,7,8,19,20,30,33,55,56,108,195,221,226,333,481,1237,1634],[3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(1935,[0,2,4,6,7,8,19,20,30,33,55,56,108,195,221,226,333,481,1237,1634],[1.7264254535265904,1.1096621248546947,1.6357552207514738,1.7213689734744655,2.0109149793643093,2.104733734581964,2.7343675094195836,2.6602595372658615,2.938462865763099,2.9967317738870745,3.6129179133108917,3.68987895444702,4.075541435259004,4.6061696863211745,4.711530201979001,4.711530201979001,5.116995310087166,5.52246041819533,6.215607598755275,6.215607598755275])|0    |\nThe fries were great too.                                                                                      |1    |[The, fry, be, great, too]                                                                                                 |[fry, great, too]                                                              |(1935,[0,6,32,109,122],[1.0,1.0,1.0,1.0,1.0])                                                                                                             |(1935,[0,6,32,109,122],[0.5754751511755302,1.7213689734744655,3.0375537684073297,4.13616605707544,4.13616605707544])                                                                                                                                                                                                                                                                                                                                      |1    |\nA great touch.                                                                                                 |1    |[A, great, touch]                                                                                                          |[great, touch]                                                                 |(1935,[32,190,570],[1.0,1.0,1.0])                                                                                                                         |(1935,[32,190,570],[3.0375537684073297,4.711530201979001,5.52246041819533])                                                                                                                                                                                                                                                                                                                                                                               |1    |\nService was very prompt.                                                                                       |1    |[Service, be, very, prompt]                                                                                                |[Service, very, prompt]                                                        |(1935,[0,25,115,1228],[1.0,1.0,1.0,1.0])                                                                                                                  |(1935,[0,25,115,1228],[0.5754751511755302,2.831217335409501,4.075541435259004,6.215607598755275])                                                                                                                                                                                                                                                                                                                                                         |1    |\nWould not go back.                                                                                             |0    |[Would, not, go, back]                                                                                                     |[Would, not, go]                                                               |(1935,[14,21,26,464],[1.0,1.0,1.0,1.0])                                                                                                                   |(1935,[14,21,26,464],[2.2837819660309497,2.6046896861110507,2.81441021709312,5.52246041819533])                                                                                                                                                                                                                                                                                                                                                           |0    |\nThe cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |0    |[The, Fasher, have, no, care, what, so, ever, on, what, I, have, to, say, it, still, end, up, be, way, override]           |[Fasher, have, no, care, ever, have, override]                                 |(1935,[0,3,5,6,7,12,27,34,51,56,57,82,95,111,149,304,314,366,1847],[1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])         |(1935,[0,3,5,6,7,12,27,34,51,56,57,82,95,111,149,304,314,366,1847],[0.5754751511755302,1.3674912341567944,1.7157979284250102,1.7213689734744655,4.021829958728619,2.3237873006446486,2.831217335409501,3.016934481204594,3.6129179133108917,3.68987895444702,3.6506582412937387,3.9130225057612296,4.018383021419056,8.27233211415088,4.4238481295272205,5.116995310087166,5.116995310087166,5.29931686688112,6.215607598755275])                         |0    |\nI tried the Cape Cod ravoli, chicken, with cranberry...mmmm!                                                   |1    |[I, try, the, Cape, Cod, revolt, chicken, with, Cranberry, mmHg]                                                           |[try, Cape, Cod, revolt, chicken, with, Cranberry, mmHg]                       |(1935,[1,3,22,112,117,927,1342,1488,1620,1890],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                 |(1935,[1,3,22,112,117,927,1342,1488,1620,1890],[1.1066364039381575,1.3674912341567944,2.674648274717961,4.269697449699962,4.13616605707544,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                    |1    |\nI was disgusted because I was pretty sure that was human hair.                                                 |0    |[I, be, disgust, because, I, be, pretty, sure, that, be, human, hair]                                                      |[disgust, pretty, sure, human, hair]                                           |(1935,[0,3,24,97,124,219,737,741,864],[3.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                              |(1935,[0,3,24,97,124,219,737,741,864],[1.7264254535265904,2.734982468313589,2.765620052923688,4.075541435259004,4.200704578213011,4.711530201979001,5.810142490647111,5.810142490647111,5.810142490647111])                                                                                                                                                                                                                                               |0    |\nI was shocked because no signs indicate cash only.                                                             |0    |[I, be, shock, because, no, sign, indicate, cash, only]                                                                    |[shock, no, sign, indicate, cash, only]                                        |(1935,[0,3,59,82,124,819,932,960,1202],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                             |(1935,[0,3,59,82,124,819,932,960,1202],[0.5754751511755302,1.3674912341567944,3.6506582412937387,3.9130225057612296,4.200704578213011,5.810142490647111,6.215607598755275,6.215607598755275,6.215607598755275])                                                                                                                                                                                                                                           |0    |\nHighly recommended.                                                                                            |1    |[Highly, recommend]                                                                                                        |[Highly, recommend]                                                            |(1935,[118,589],[1.0,1.0])                                                                                                                                |(1935,[118,589],[4.13616605707544,5.810142490647111])                                                                                                                                                                                                                                                                                                                                                                                                     |1    |\nWaitress was a little slow in service.                                                                         |0    |[Waitress, be, a, little, slow, in, service]                                                                               |[Waitress, slow, service]                                                      |(1935,[0,4,15,23,153,158,516],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                              |(1935,[0,4,15,23,153,158,516],[0.5754751511755302,1.6357552207514738,2.3237873006446486,2.6320886602991656,4.51085950651685,4.51085950651685,5.52246041819533])                                                                                                                                                                                                                                                                                           |0    |\nThis place is not worth your time, let alone Vegas.                                                            |0    |[This, place, be, not, worth, you, time, let, alone, Vegas]                                                                |[place, not, worth, time, Vegas]                                               |(1935,[0,10,14,19,30,36,72,157,565,1250],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                       |(1935,[0,10,14,19,30,36,72,157,565,1250],[0.5754751511755302,2.226623552191001,2.2837819660309497,2.7343675094195836,2.938462865763099,3.058607177605162,3.7732605633860707,4.51085950651685,5.52246041819533,6.215607598755275])                                                                                                                                                                                                                         |0    |\ndid not like at all.                                                                                           |0    |[do, not, like, at, all]                                                                                                   |[do, not, like]                                                                |(1935,[14,31,33,37,39],[1.0,1.0,1.0,1.0,1.0])                                                                                                             |(1935,[14,31,33,37,39],[2.2837819660309497,2.938462865763099,2.9967317738870745,3.245193133185574,3.353406717825807])                                                                                                                                                                                                                                                                                                                                     |0    |\n+---------------------------------------------------------------------------------------------------------------+-----+---------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\nonly showing top 20 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A new spell checker, as well as a custom RegEx fixed my issues so far. There are still some errors in the first few rows (i.e. ravoli -> revolt; overpriced -> override), but these are hard to fix and I have to accept some level of error, especially on my first ever NLP project. I still want to explore using a stopword filter, but I'm not quite sure at this point how to ensure I keep contextual descriptors like 'not'. I've tried both pretrained stop-word models available in the spark-nlp library. These are build on the pyspark.ml.features.StopWordsRemover, so that wouldn't work either. My last, very rudimentary option, is to do a custom stop-word list.\n",
        "\n",
        "I'm simply going to look through the first 25 rows and pick out any words I don't believe are necessary. Later on I may use a count vectorizer to find the terms with the most frequency, however this will take a long computation time and for now, I just want to get a prototype working."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "970d2c02-8008-43a8-b5fd-bab8f1fcfbe4"
        },
        "id": "qT43vMgp0W0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization\n",
        "\n",
        "The text now needs to be given a numeric format for usage by the ML classifier. To my knowledge, there are two paradigms in which this can be done; text-frequency based, and pretrained-embeddings based. For this first project, I will be using text-frequency based vectorization, and I will be using a count vectorizer followed by an IDF."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "082ff8af-30ba-46be-aa01-2015c1004826"
        },
        "id": "BllrGYUf0W0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['the', 'be', 'now', 'get', 'on', 'and', 'so', 'want', 'I', 'it', 'that', 'honesty', 'you', 'they', 'them', 'this', 'by', 'during', 'holiday', 'off', 'back', 'what',\n",
        "             'say', 'to', 'still', 'end', 'up', 'way', 'little', 'in', 'let', 'alone', 'at', 'all', 'because', 'oh', 'stuff', 'red', 'that\\'s', 'a', 'of', 'some']\n",
        "\n",
        "remover = StopWordsRemover(stopWords = stop_words)\\\n",
        "            .setInputCol('finished')\\\n",
        "            .setOutputCol('cleaned')\n",
        "\n",
        "finisher = Finisher()\\\n",
        "                .setInputCols('lemma')\\\n",
        "                .setOutputCols('finished')\n",
        "\n",
        "countVec = CountVectorizer()\\\n",
        "            .setInputCol('finished')\\\n",
        "            .setOutputCol('rawFeatures')\n",
        "\n",
        "idf = IDF()\\\n",
        "            .setInputCol('rawFeatures')\\\n",
        "            .setOutputCol('features')\n",
        "\n",
        "pipeline = Pipeline().setStages([document, sentence, tokenizer, checker, lemmatizer, finisher, remover, countVec, idf])\n",
        "model = pipeline.fit(df)\n",
        "result = model.transform(df)\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "adc3c041-33c2-452b-8303-824adb434725"
        },
        "id": "unzzvbrA0W0d",
        "outputId": "7ac4ad64-2a22-4254-c3dd-29c5bab69403"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n|              Review|Liked|            finished|             cleaned|         rawFeatures|            features|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n|Wow... Loved this...|    1|[Wow, Loved, this...| [Wow, Loved, place]|(1935,[10,17,810,...|(1935,[10,17,810,...|\n|  Crust is not good.|    0|[Crust, be, not, ...|  [Crust, not, good]|(1935,[0,11,14,12...|(1935,[0,11,14,12...|\n|Not tasty and the...|    0|[Not, tasty, and,...|[Not, tasty, text...|(1935,[0,1,2,43,1...|(1935,[0,1,2,43,1...|\n|Stopped by during...|    1|[Stopped, by, dur...|[Stopped, late, M...|(1935,[1,2,12,58,...|(1935,[1,2,12,58,...|\n|The selection on ...|    1|[The, selection, ...|[selection, menu,...|(1935,[0,1,2,6,27...|(1935,[0,1,2,6,27...|\n|Now I am getting ...|    0|[Now, I, be, get,...|  [angry, damn, Rho]|(1935,[0,2,3,18,3...|(1935,[0,2,3,18,3...|\n|Honeslty it didn&#39;...|    0|[Honesty, it, did...|[didn&#39;t, taste, f...|(1935,[12,77,126,...|(1935,[12,77,126,...|\n|The potatoes were...|    0|[The, potato, be,...|[potato, like, ru...|(1935,[0,2,4,6,7,...|(1935,[0,2,4,6,7,...|\n|The fries were gr...|    1|[The, fry, be, gr...|   [fry, great, too]|(1935,[0,6,32,109...|(1935,[0,6,32,109...|\n|      A great touch.|    1|   [A, great, touch]|      [great, touch]|(1935,[32,190,570...|(1935,[32,190,570...|\n|Service was very ...|    1|[Service, be, ver...|[Service, very, p...|(1935,[0,25,115,1...|(1935,[0,25,115,1...|\n|  Would not go back.|    0|[Would, not, go, ...|    [Would, not, go]|(1935,[14,21,26,4...|(1935,[14,21,26,4...|\n|The cashier had n...|    0|[The, Fasher, hav...|[Fasher, have, no...|(1935,[0,3,5,6,7,...|(1935,[0,3,5,6,7,...|\n|I tried the Cape ...|    1|[I, try, the, Cap...|[try, Cape, Cod, ...|(1935,[1,3,22,112...|(1935,[1,3,22,112...|\n|I was disgusted b...|    0|[I, be, disgust, ...|[disgust, pretty,...|(1935,[0,3,24,97,...|(1935,[0,3,24,97,...|\n|I was shocked bec...|    0|[I, be, shock, be...|[shock, no, sign,...|(1935,[0,3,59,82,...|(1935,[0,3,59,82,...|\n| Highly recommended.|    1| [Highly, recommend]| [Highly, recommend]|(1935,[118,589],[...|(1935,[118,589],[...|\n|Waitress was a li...|    0|[Waitress, be, a,...|[Waitress, slow, ...|(1935,[0,4,15,23,...|(1935,[0,4,15,23,...|\n|This place is not...|    0|[This, place, be,...|[place, not, wort...|(1935,[0,10,14,19...|(1935,[0,10,14,19...|\n|did not like at all.|    0|[do, not, like, a...|     [do, not, like]|(1935,[14,31,33,3...|(1935,[14,31,33,3...|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n              Review|Liked|            finished|             cleaned|         rawFeatures|            features|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\nWow... Loved this...|    1|[Wow, Loved, this...| [Wow, Loved, place]|(1935,[10,17,810,...|(1935,[10,17,810,...|\n  Crust is not good.|    0|[Crust, be, not, ...|  [Crust, not, good]|(1935,[0,11,14,12...|(1935,[0,11,14,12...|\nNot tasty and the...|    0|[Not, tasty, and,...|[Not, tasty, text...|(1935,[0,1,2,43,1...|(1935,[0,1,2,43,1...|\nStopped by during...|    1|[Stopped, by, dur...|[Stopped, late, M...|(1935,[1,2,12,58,...|(1935,[1,2,12,58,...|\nThe selection on ...|    1|[The, selection, ...|[selection, menu,...|(1935,[0,1,2,6,27...|(1935,[0,1,2,6,27...|\nNow I am getting ...|    0|[Now, I, be, get,...|  [angry, damn, Rho]|(1935,[0,2,3,18,3...|(1935,[0,2,3,18,3...|\nHoneslty it didn&#39;...|    0|[Honesty, it, did...|[didn&#39;t, taste, f...|(1935,[12,77,126,...|(1935,[12,77,126,...|\nThe potatoes were...|    0|[The, potato, be,...|[potato, like, ru...|(1935,[0,2,4,6,7,...|(1935,[0,2,4,6,7,...|\nThe fries were gr...|    1|[The, fry, be, gr...|   [fry, great, too]|(1935,[0,6,32,109...|(1935,[0,6,32,109...|\n      A great touch.|    1|   [A, great, touch]|      [great, touch]|(1935,[32,190,570...|(1935,[32,190,570...|\nService was very ...|    1|[Service, be, ver...|[Service, very, p...|(1935,[0,25,115,1...|(1935,[0,25,115,1...|\n  Would not go back.|    0|[Would, not, go, ...|    [Would, not, go]|(1935,[14,21,26,4...|(1935,[14,21,26,4...|\nThe cashier had n...|    0|[The, Fasher, hav...|[Fasher, have, no...|(1935,[0,3,5,6,7,...|(1935,[0,3,5,6,7,...|\nI tried the Cape ...|    1|[I, try, the, Cap...|[try, Cape, Cod, ...|(1935,[1,3,22,112...|(1935,[1,3,22,112...|\nI was disgusted b...|    0|[I, be, disgust, ...|[disgust, pretty,...|(1935,[0,3,24,97,...|(1935,[0,3,24,97,...|\nI was shocked bec...|    0|[I, be, shock, be...|[shock, no, sign,...|(1935,[0,3,59,82,...|(1935,[0,3,59,82,...|\n Highly recommended.|    1| [Highly, recommend]| [Highly, recommend]|(1935,[118,589],[...|(1935,[118,589],[...|\nWaitress was a li...|    0|[Waitress, be, a,...|[Waitress, slow, ...|(1935,[0,4,15,23,...|(1935,[0,4,15,23,...|\nThis place is not...|    0|[This, place, be,...|[place, not, wort...|(1935,[0,10,14,19...|(1935,[0,10,14,19...|\ndid not like at all.|    0|[do, not, like, a...|     [do, not, like]|(1935,[14,31,33,3...|(1935,[14,31,33,3...|\n+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "On second thought, once the model is trained, it would in-fact be useful to have a CountVectorization map rather than a hashmap. The ability to distinguish which buzz-words are associated with positive and negative reviews is quite useful, and it is cumbersome to do this with a hashed count. It only takes around 4-5 minutes to run on this small dataset, so it's not bad at all, actually. I really want to get some predictions going."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d033f28c-b653-483c-97a9-5234e4770184"
        },
        "id": "47UN-ACn0W0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training and evaluation\n",
        "\n",
        "Finally I can train a model on this very rough pipeline. I simply want to get a prototype working so that I can understand all I have until now. Afterwards, I will set up a proper full-length pipeline with several models to try and hyperparameter tuning. For now, I will train on a LogisticRegression classifier (weird name)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "7ed8b10d-8fc2-41b7-8f6c-0d3c84e4fb84"
        },
        "id": "v_0XNlR30W0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = result.withColumn('label', col('Liked')).select(['features', 'label'])\n",
        "model_data.show(5)\n",
        "\n",
        "train, test = model_data.randomSplit([0.9, 0.1], seed=31415)\n",
        "train.show()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "baccfe31-5e8e-4d3f-a914-fcea94d2abef"
        },
        "id": "LqvXFC7M0W0e",
        "outputId": "5e271d3d-5714-4133-bc5e-6a6e8afb331b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|(1935,[10,17,810,...|    1|\n|(1935,[0,11,14,12...|    0|\n|(1935,[0,1,2,43,1...|    0|\n|(1935,[1,2,12,58,...|    1|\n|(1935,[0,1,2,6,27...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|(1935,[0,1,2,3,4,...|    1|\n|(1935,[0,1,2,3,4,...|    1|\n|(1935,[0,1,2,3,4,...|    1|\n|(1935,[0,1,2,3,4,...|    0|\n|(1935,[0,1,2,3,4,...|    1|\n|(1935,[0,1,2,3,5,...|    0|\n|(1935,[0,1,2,3,5,...|    0|\n|(1935,[0,1,2,3,5,...|    0|\n|(1935,[0,1,2,3,6,...|    0|\n|(1935,[0,1,2,3,6,...|    0|\n|(1935,[0,1,2,3,6,...|    1|\n|(1935,[0,1,2,3,7,...|    1|\n|(1935,[0,1,2,3,7,...|    1|\n|(1935,[0,1,2,3,7,...|    0|\n|(1935,[0,1,2,3,7,...|    1|\n|(1935,[0,1,2,3,7,...|    1|\n|(1935,[0,1,2,3,8,...|    0|\n|(1935,[0,1,2,3,8,...|    1|\n|(1935,[0,1,2,3,8,...|    0|\n|(1935,[0,1,2,3,9,...|    1|\n+--------------------+-----+\nonly showing top 20 rows\n\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n            features|label|\n+--------------------+-----+\n(1935,[10,17,810,...|    1|\n(1935,[0,11,14,12...|    0|\n(1935,[0,1,2,43,1...|    0|\n(1935,[1,2,12,58,...|    1|\n(1935,[0,1,2,6,27...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n+--------------------+-----+\n            features|label|\n+--------------------+-----+\n(1935,[0,1,2,3,4,...|    1|\n(1935,[0,1,2,3,4,...|    1|\n(1935,[0,1,2,3,4,...|    1|\n(1935,[0,1,2,3,4,...|    0|\n(1935,[0,1,2,3,4,...|    1|\n(1935,[0,1,2,3,5,...|    0|\n(1935,[0,1,2,3,5,...|    0|\n(1935,[0,1,2,3,5,...|    0|\n(1935,[0,1,2,3,6,...|    0|\n(1935,[0,1,2,3,6,...|    0|\n(1935,[0,1,2,3,6,...|    1|\n(1935,[0,1,2,3,7,...|    1|\n(1935,[0,1,2,3,7,...|    1|\n(1935,[0,1,2,3,7,...|    0|\n(1935,[0,1,2,3,7,...|    1|\n(1935,[0,1,2,3,7,...|    1|\n(1935,[0,1,2,3,8,...|    0|\n(1935,[0,1,2,3,8,...|    1|\n(1935,[0,1,2,3,8,...|    0|\n(1935,[0,1,2,3,9,...|    1|\n+--------------------+-----+\nonly showing top 20 rows\n\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lrModel = lr.fit(train)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "0dcfe917-4ded-4e26-9f09-9ec23bc59daa"
        },
        "id": "psqouN4P0W0e",
        "outputId": "3777a0a3-94af-45d0-ba69-70006610f1fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pred = lrModel.evaluate(test)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "559bea28-be28-4bb5-9590-adb9a333a1a8"
        },
        "id": "pEIONpj10W0e",
        "outputId": "fa181c74-f25d-4131-c39f-220109bdf475"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pred.accuracy"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "3f4c6e74-4616-4ec8-99c9-3780391c17f4"
        },
        "id": "C--RgB0B0W0e",
        "outputId": "14eeb905-5694-4d61-f909-682be870a996"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[91]: 0.7659574468085106</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[91]: 0.7659574468085106</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together\n",
        "\n",
        "Now I can start looking at training entire pipelined models, applying grid searches on parameters, and testing different models. I will now describe a high-level summary of the tasks to be completed:\n",
        "\n",
        "1) Pipeline for initial data processing, including the following steps:\n",
        "    * Document, Sentencing -- Standard\n",
        "    * Tokenization -- Standard\n",
        "    * Spell checking -- ContextSpellChecker provided the best results in the exploration phase above\n",
        "    * Lemmatization -- Standard\n",
        "    * Stop-word removal -- Need to test several approaches:\n",
        "        * No stop-words\n",
        "        * Custom list as used above\n",
        "        * Pretrained model\n",
        "    * Finisher (Standard)\n",
        "    * HashingTF (For speed vs CountVectorizer)\n",
        "    * IDF Layer (Standard)\n",
        "    \n",
        "2) Model pipelines constructed where previous pipeline ends:\n",
        "    * One for each model to be tested\n",
        "    * Use cross validation and parameter grids to identify strongest candidates\n",
        "    \n",
        "The model pipelines will be separate from the data processing pipeline due to the fact that the data processing pipeline will be identical regardless of the model used. This will cut down on compute time at the cost of memory. Currently, memory is not an issue."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2d4796f5-8b6d-4172-98c9-308817dcf3c6"
        },
        "id": "XAIM_ccq0W0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import RegexTokenizer, HashingTF, IDF, StopWordsRemover\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel, TrainValidationSplit\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import * # Change once all used modules are known\n",
        "from sparknlp.base import * # Change once all used modules are known"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "81cae6ad-bd80-4839-8c07-c77c17193f00"
        },
        "id": "uUi4D87X0W0g",
        "outputId": "ef324099-3541-4cb0-f518-3c6a0f05e10a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ---=== Base pipeline with pretrained stopwords ===---\n",
        "\n",
        "document = DocumentAssembler()\\\n",
        "                .setInputCol('Review')\\\n",
        "                .setOutputCol('document')\\\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "                .setInputCols('document')\\\n",
        "                .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = RegexTokenizer()\\\n",
        "                .setInputCols('sentence')\\\n",
        "                .setOutputCol('token')\\\n",
        "                .setPattern(r'[^a-zA-Z0-9_\\']')\n",
        "\n",
        "checker = ContextSpellCheckerModel\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols(\"token\")\\\n",
        "                .setOutputCol(\"checked\")\n",
        "\n",
        "lemmatizer = LemmatizerModel()\\\n",
        "                .pretrained()\\\n",
        "                .setInputCols('checked')\\\n",
        "                .setOutputCol('lemma')\n",
        "\n",
        "stopwords = StopWordsCleaner()\\\n",
        "                .pretrained('stopwords_iso', 'en')\\\n",
        "                .setInputCols('lemma')\\\n",
        "                .setOutputCol('cleaned')\n",
        "\n",
        "finisher = Finisher()\\\n",
        "                .setInputCols('cleaned')\\\n",
        "                .setOutputCols('finished')\n",
        "\n",
        "hashingTF = HashingTF()\\\n",
        "                .setInputCol('finished')\\\n",
        "                .setOutputCol('rawFeatures')\n",
        "\n",
        "idf = IDF()\\\n",
        "                .setInputCol('rawFeatures')\\\n",
        "                .setOutputCol('features')\n",
        "\n",
        "pipe_sw_pre = Pipeline()\\\n",
        "                .setStages([document, sentence, tokenizer, checker, \n",
        "                            lemmatizer, stopwords, finisher, hashingTF, idf])\n",
        "\n",
        "# ---=== Custom stop words in the pipeline ===---\n",
        "\n",
        "stop_words = ['the', 'be', 'now', 'get', 'on', 'and', 'so', 'want', 'I', 'it', 'that', 'honesty', 'you', 'they', 'them', 'this', 'by', 'during', 'holiday', 'off', 'back', 'what',\n",
        "             'say', 'to', 'still', 'end', 'up', 'way', 'little', 'in', 'let', 'alone', 'at', 'all', 'because', 'oh', 'stuff', 'red', 'that\\'s', 'a', 'of', 'some']\n",
        "\n",
        "finisher.setInputCols('lemma')\\\n",
        "        .setOutputCols('finished')\n",
        "\n",
        "stopwords = StopWordsRemover(stopWords = stop_words)\\\n",
        "                .setInputCol('finished')\\\n",
        "                .setOutputCol('cleaned')\n",
        "\n",
        "hashingTF.setInputCol('cleaned')\\\n",
        "         .setOutputCol('rawFeatures')\n",
        "                \n",
        "\n",
        "pipe_sw_cstm = Pipeline()\\\n",
        "                .setStages([document, sentence, tokenizer, checker, \n",
        "                            lemmatizer, finisher, stopwords, hashingTF, idf])\n",
        "\n",
        "# ---=== No stop words in the pipeline ===---\n",
        "\n",
        "finisher.setInputCols('lemma')\\\n",
        "        .setOutputCols('finished')\n",
        "\n",
        "hashingTF.setInputCol('finished')\\\n",
        "         .setOutputCol('rawFeatures')\n",
        "\n",
        "pipe_sw_none = Pipeline()\\\n",
        "                .setStages([document, sentence, tokenizer, checker, \n",
        "                            lemmatizer, finisher, hashingTF, idf])"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2d5c9c83-964c-472c-8fa7-17333f88b5cc"
        },
        "id": "BI_rWkH20W0g",
        "outputId": "0066ee01-5872-4bfa-ff2e-b29473c07b8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[OK!]\nstopwords_iso download started this may take some time.\nApproximate size to download 2.1 KB\n\r[ | ]\r[OK!]\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[ | ]\r[ / ]\r[ â€” ]\r[ \\ ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[ / ]\r[OK!]\nstopwords_iso download started this may take some time.\nApproximate size to download 2.1 KB\n\r[ | ]\r[OK!]\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wish to use a classification model that allows for explainability of the data. This is a supervised classification problem, and so the possible models I am aware of that meet these criteria are Decision Trees and Logistic Regression. I will start with random-ish values for the parameters and adjust as results come in."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8b7efac4-aa8f-4070-88b1-1f022bc5246c"
        },
        "id": "YetSgVgI0W0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr_params = ParamGridBuilder()\\\n",
        "            .addGrid(lr.regParam, [0.1, 0.01])\\\n",
        "            .addGrid(lr.maxIter, [1, 5, 10, 25])\\\n",
        "            .build()\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt_params = ParamGridBuilder()\\\n",
        "            .addGrid(dt.maxBins, [10,50,100])\\\n",
        "            .addGrid(dt.maxDepth, [10, 50, 100])\\\n",
        "            .build()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6aefb35d-40c4-4f28-a1fd-7c17bb2605a7"
        },
        "id": "UtpBP5SY0W0h",
        "outputId": "15f0fb63-014b-4d22-9dbb-63ec4d10873b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = sqlContext.sql(\"Select * FROM nlp_restaurant_reviews\")\n",
        "df = df.withColumn('label', col('Liked')).select(['label', 'Review'])\n",
        "train, test = df.randomSplit([0.8, 0.2], seed = 31415)\n",
        "\n",
        "model_info = {\n",
        "    'lr' : lr,\n",
        "    'dt' : dt\n",
        "}\n",
        "\n",
        "param_info = {\n",
        "    'lr' : lr_params,\n",
        "    'dt' : dt_params\n",
        "}\n",
        "\n",
        "pipe_info = {\n",
        "    'sw_pre' : pipe_sw_pre,\n",
        "    'sw_cstm' : pipe_sw_cstm,\n",
        "    'sw_none' : pipe_sw_none\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# , pipe_sw_custom, pipe_sw_none\n",
        "# , 'dt'\n",
        "\n",
        "# I will be constructing a JSON-like list containing the results of the calculations.\n",
        "        \n",
        "\"\"\"\n",
        "cv = TrainValidationSplit(estimator = pipe_added,\n",
        "                   estimatorParamMaps = lr_params,\n",
        "                   evaluator = BinaryClassificationEvaluator(),\n",
        "                   seed = 31415,\n",
        "                   parallelism=1\n",
        ")\n",
        "\n",
        "cvModel = cv.fit(train)\n",
        "pred = cvModel.transform(test)\n",
        "\"\"\""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f0c0f081-b5a2-48e5-957d-8acb3ba406da"
        },
        "id": "WVr-Pm-B0W0h",
        "outputId": "eabe9c3d-9d64-4d5a-db99-e79f8306bcde"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[10]: &#39;\\ncv = TrainValidationSplit(estimator = pipe_added,\\n                   estimatorParamMaps = lr_params,\\n                   evaluator = BinaryClassificationEvaluator(),\\n                   seed = 31415,\\n                   parallelism=1\\n)\\n\\ncvModel = cv.fit(train)\\npred = cvModel.transform(test)\\n&#39;</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: &#39;\\ncv = TrainValidationSplit(estimator = pipe_added,\\n                   estimatorParamMaps = lr_params,\\n                   evaluator = BinaryClassificationEvaluator(),\\n                   seed = 31415,\\n                   parallelism=1\\n)\\n\\ncvModel = cv.fit(train)\\npred = cvModel.transform(test)\\n&#39;</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wanted to use the CrossValidator object to test different parameter distributions as well as the separate models, however, I was running into an error with no documentation online. I've posted a StackOverflow request but to no avail. For now, I will forego the hyperparameter tuning by use of CrossValidator (TrainValidationSplit raised same error) and simply test the different pipelines with default parameters."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2cdfc392-8769-4461-83fc-c2822def4bd8"
        },
        "id": "FP0P7wZ30W0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_info = {}\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "df = sqlContext.sql(\"Select * FROM nlp_restaurant_reviews\")\n",
        "df = df.withColumn('label', col('Liked')).select(['label', 'Review'])\n",
        "\n",
        "for pipe_label, pipe in pipe_info.items():\n",
        "    model_results = {}\n",
        "\n",
        "    for model_label, model in model_info.items():\n",
        "        train, test = df.randomSplit([0.8, 0.2], seed = 31415)\n",
        "        \n",
        "        pipe_added = Pipeline().setStages([pipe, model])\n",
        "        pipe_trained = pipe_added.fit(train)\n",
        "        \n",
        "        pipe_data = pipe_trained.transform(test)\n",
        "        areaUnderROC = evaluator.evaluate(pipe_data)\n",
        "        \n",
        "        print(f'{pipe_label} - {model_label}: {areaUnderROC}')\n",
        "        model_results[model_label] = areaUnderROC\n",
        "        \n",
        "        del pipe_data\n",
        "        \n",
        "    results_info[pipe_label] = model_results"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "18cfa8a3-ae10-456f-b47a-b3782552e003"
        },
        "id": "PXvC3kgQ0W0h",
        "outputId": "c91a2ff5-ce99-4b77-c7c1-7a8b9b954990"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">sw_pre - lr: 0.8132022471910118\nsw_pre - dt: 0.4323501872659177\nsw_cstm - lr: 0.8132022471910118\nsw_cstm - dt: 0.4323501872659177\nsw_none - lr: 0.8132022471910118\nsw_none - dt: 0.4323501872659177\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sw_pre - lr: 0.8132022471910118\nsw_pre - dt: 0.4323501872659177\nsw_cstm - lr: 0.8132022471910118\nsw_cstm - dt: 0.4323501872659177\nsw_none - lr: 0.8132022471910118\nsw_none - dt: 0.4323501872659177\n</div>"
            ]
          }
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is clearly something else going on here, it is extremely unlikely that all three pipelines perform exactly the same. Either my pipelines are being instanced to the same memory locations, or there is a leak in my loop. Regardless, it would seem that the LogisticRegression classification works significantly better than the Decision Tree. Since this is a binary classification, if the accuracy of the Decision Tree is <0.5 I can simply take the complement to achieve a true prediction accuracy >0.5. The above metric however is the area under the ROC curve, and so I should look at the accuracy specifically if I want to apply that reasoning."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4cc0d77f-327d-4c4d-97da-d0f71263382e"
        },
        "id": "E396rW340W0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "f2545269-22b6-43c0-9aea-39fa2e38b22a"
        },
        "id": "4SsHLE4V0W0i"
      },
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "nlp-restaurant_reviews-git",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 4240063581689414
    },
    "colab": {
      "name": "nlp-restaurant_reviews-git(1).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}